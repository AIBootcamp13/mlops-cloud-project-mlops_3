import requests
from io import StringIO
import pandas as pd
import requests
from tqdm import tqdm
from dotenv import load_dotenv
import os
from datetime import datetime, timedelta
import s3fs
import os
import sys
sys.path.append(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
)
from data.utils.constants import (
    KMA_STATION_ID,
    KMA_API_URL,
    WEATHER_COLUMNS,
    WEATHER_KOREAN_COLUMNS,
    LOOKBACK_DAYS,
)

load_dotenv()

import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
logger.info("This will be printed in terminal")

# AWS ìê²© ì¦ëª… í™•ì¸
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')
AWS_DEFAULT_REGION = os.getenv('AWS_DEFAULT_REGION')
S3_BUCKET_NAME = os.getenv('S3_BUCKET_NAME')

def fetch_weather_data(start_datetime: str, end_datetime: str) -> pd.DataFrame:
    """
    ê¸°ìƒì²­ APIì—ì„œ ë‚ ì”¨ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        start_datetime (str): ì‹œì‘ ë‚ ì§œ/ì‹œê°„ (YYYYMMDDHHMM í˜•ì‹)
        end_datetime (str): ì¢…ë£Œ ë‚ ì§œ/ì‹œê°„ (YYYYMMDDHHMM í˜•ì‹)
    
    Returns:
        pd.DataFrame: ê°€ì ¸ì˜¨ ë‚ ì”¨ ë°ì´í„°
    """
    api_params = {
        "tm1": start_datetime,
        "tm2": end_datetime,
        "stn": KMA_STATION_ID,
        "authKey": os.getenv('AUTH_KEY'),
        "help": 0
    }
    
    response = requests.get(KMA_API_URL, params=api_params)
    raw_data = response.text
    
    use_korean_columns = False
    
    data_lines = [line for line in raw_data.strip().split("\n") if not line.startswith("#")]
    
    return pd.read_csv(
        StringIO("\n".join(data_lines)),
        sep=r'\s+',
        header=None,
        names= WEATHER_KOREAN_COLUMNS if use_korean_columns else WEATHER_COLUMNS
    )

def generate_date_ranges(start_date: datetime, end_date: datetime) -> list:
    """
    ì£¼ì–´ì§„ ê¸°ê°„ì„ BATCH_DAYS ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ë‚ ì§œ ë²”ìœ„ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        start_date (datetime): ì‹œì‘ ë‚ ì§œ
        end_date (datetime): ì¢…ë£Œ ë‚ ì§œ
    
    Returns:
        list: (ì‹œì‘ë‚ ì§œ, ì¢…ë£Œë‚ ì§œ) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
    """
    start_date = start_date.replace(minute=0, second=0, microsecond=0)
    end_date = end_date.replace(minute=0, second=0, microsecond=0)

    date_ranges = []
    current_start = start_date

    while current_start <= end_date:
        current_end = min(current_start + timedelta(days=LOOKBACK_DAYS), end_date)
        current_end = current_end.replace(hour=23)

        start_str = current_start.strftime('%Y%m%d%H%M')
        end_str = current_end.strftime('%Y%m%d%H%M')

        date_ranges.append((start_str, end_str))
        current_start = current_end + timedelta(hours=1)
    
    return date_ranges

def get_latest_weather_data() -> datetime:
    """
    S3ì—ì„œ ê°€ì¥ ìµœê·¼ ë‚ ì”¨ ë°ì´í„°ì˜ ì‹œê°„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    íŒŒì¼ ê²½ë¡œì˜ ë§ˆì§€ë§‰ ë‚ ì§œì™€ parquet íŒŒì¼ ë‚´ì˜ ë§ˆì§€ë§‰ ì‹œê°„ì„ ëª¨ë‘ í™•ì¸í•©ë‹ˆë‹¤.
    """
    s3 = s3fs.S3FileSystem()
    try:
        # S3 ë²„í‚·ì—ì„œ ê°€ì¥ ìµœê·¼ ë°ì´í„° íŒŒì¼ ì°¾ê¸°
        files = s3.glob(f"{S3_BUCKET_NAME}/data/weather/raw/*/*/*/data.parquet")
        if not files:
            return datetime(2000, 1, 1)
        
        # íŒŒì¼ ê²½ë¡œì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
        latest_file = max(files)
        
        # í•´ë‹¹ ë‚ ì§œì˜ parquet íŒŒì¼ì—ì„œ ë§ˆì§€ë§‰ ì‹œê°„ í™•ì¸
        df = pd.read_parquet(latest_file, filesystem=s3)
        last_time = pd.to_datetime(df['ObservationTime']).max()
        return last_time
            
    except Exception as e:
        print(f"S3ì—ì„œ ìµœì‹  ë°ì´í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return datetime(2000, 1, 1)

def save_to_s3(df: pd.DataFrame, year: int, month: int, day: int):
    """
    ë°ì´í„°í”„ë ˆì„ì„ S3ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    s3 = s3fs.S3FileSystem()
    path = f"{S3_BUCKET_NAME}/data/weather/raw/year={year:04d}/month={month:02d}/day={day:02d}/data.parquet"
    try:
        df.to_parquet(path, index=False, engine='pyarrow', filesystem=s3)
    except Exception as e:
        print(f"S3 ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def initialize_weather_database():
    """
    ì „ì²´ ë‚ ì”¨ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ S3ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    start_date = datetime(2000, 1, 1)
    end_date = datetime.now()
    date_ranges = generate_date_ranges(start_date, end_date)
    
    weather_data_frames = []
    for start_time, end_time in tqdm(date_ranges, desc="ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘ ì¤‘"):
        weather_data_frames.append(fetch_weather_data(start_time, end_time))
    
    combined_data = pd.concat(weather_data_frames)
    combined_data['ObservationTime'] = pd.to_datetime(combined_data['ObservationTime'], format='%Y%m%d%H%M')
    combined_data['year'] = combined_data['ObservationTime'].dt.year
    combined_data['month'] = combined_data['ObservationTime'].dt.month
    combined_data['day'] = combined_data['ObservationTime'].dt.day
    combined_data['hour'] = combined_data['ObservationTime'].dt.hour
    
    # ì¼ë³„ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì–´ S3ì— ì €ì¥
    for (year, month, day), group_df in tqdm(combined_data.groupby(['year', 'month', 'day'])):
        group_df.drop(columns=['year', 'month', 'day'], inplace=True)
        save_to_s3(group_df, year, month, day)

def update_weather_database():
    """
    S3ì˜ ìµœì‹  ë°ì´í„° ì´í›„ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ë‚ ì”¨ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    last_observation = get_latest_weather_data()
    print("ğŸ” ë§ˆì§€ë§‰ ê´€ì¸¡ ì‹œê°„:", last_observation)  # ì¶”ê°€!

    start_time = last_observation + timedelta(hours=1)
    end_time = datetime.now()
    
    if start_time >= end_time:
        print("ì´ë¯¸ ìµœì‹  ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤.")
        return
    
    date_ranges = generate_date_ranges(start_time, end_time)
    weather_data_frames = []
    
    for start_time, end_time in tqdm(date_ranges, desc="ë‚ ì”¨ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘"):
        weather_data_frames.append(fetch_weather_data(start_time, end_time))
    
    if weather_data_frames:
        new_data = pd.concat(weather_data_frames)
        new_data['ObservationTime'] = pd.to_datetime(new_data['ObservationTime'], format='%Y%m%d%H%M')
        new_data['year'] = new_data['ObservationTime'].dt.year
        new_data['month'] = new_data['ObservationTime'].dt.month
        new_data['day'] = new_data['ObservationTime'].dt.day
        new_data['hour'] = new_data['ObservationTime'].dt.hour
        
        # ì¼ë³„ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì–´ S3ì— ì €ì¥
        for (year, month, day), group_df in new_data.groupby(['year', 'month', 'day']):
            group_df.drop(columns=['year', 'month', 'day'], inplace=True)
            save_to_s3(group_df, year, month, day)

def check_s3_path_exists() -> bool:
    """
    S3ì— weather ë°ì´í„° ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    """
    s3 = s3fs.S3FileSystem()
    try:
        # weather í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
        weather_path = f"{S3_BUCKET_NAME}/data/weather/raw"
        return s3.exists(weather_path) and len(s3.ls(weather_path)) > 0
    except Exception as e:
        print(f"S3 ê²½ë¡œ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def collect_weather_data_with_time():
    """
    S3ì— weather ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”í•˜ê³ , ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    if check_s3_path_exists():
        print("ê¸°ì¡´ ë‚ ì”¨ ë°ì´í„°ê°€ ë°œê²¬ë˜ì–´ ì—…ë°ì´íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        update_weather_database()
    else:
        print("ê¸°ì¡´ ë‚ ì”¨ ë°ì´í„°ê°€ ì—†ì–´ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        initialize_weather_database()

if __name__ == "__main__":
    collect_weather_data_with_time()
    
    
    
    
    
    
    
