# FROM python:3.8-slim

# COPY requirements.txt /tmp
# RUN pip install -r /tmp/requirements.txt

# ENV TZ=Asia/Seoul
# RUN apt-get update && \
#       apt-get install -y gcc libc-dev vim && \
#       rm -rf /var/lib/apt/lists/*

# RUN pip install apache-airflow
# ENV AIRFLOW_HOME=/opt/airflow
# ENV AIRFLOW__CORE__LOAD_EXAMPLES=False
# RUN mkdir -p $AIRFLOW_HOME
# WORKDIR $AIRFLOW_HOME

# COPY airflow/dags /opt/airflow/dags
# COPY data /opt/data
# COPY .env /opt/.env

# RUN airflow db init

# EXPOSE 8181

# COPY airflow.start.sh /opt/airflow.start.sh
# RUN chmod +x /opt/airflow.start.sh

# ENV PYTHONPATH="/opt"

# # 시작 스크립트 실행
# CMD ["/opt/airflow.start.sh"]

# 주석: 도커 실행 명령어
# docker build -t mlops-data-airflow-image -f .\mlops_team\Dockerfile.airflow .
# docker run -p 8181:8181 --name mlops-data-airflow mlops-data-airflow-image
# airflow dags reserialize

# mlops_team/Dockerfile.airflow

FROM python:3.8-slim

COPY requirements.txt /tmp
RUN pip install -r /tmp/requirements.txt

ENV TZ=Asia/Seoul
RUN apt-get update && \
    apt-get install -y gcc libc-dev vim && \
    rm -rf /var/lib/apt/lists/*

RUN pip install apache-airflow
ENV AIRFLOW_HOME=/opt/airflow
ENV AIRFLOW__CORE__LOAD_EXAMPLES=False
RUN mkdir -p $AIRFLOW_HOME
WORKDIR $AIRFLOW_HOME

COPY airflow/dags /opt/airflow/dags
COPY data /opt/data
COPY .env /opt/.env
COPY airflow.start.sh /opt/airflow.start.sh
RUN chmod +x /opt/airflow.start.sh

EXPOSE 8181
CMD ["/opt/airflow.start.sh"]